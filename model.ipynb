{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de3bfaf-0137-4f61-8931-fcbf4c888ba7",
   "metadata": {},
   "source": [
    "# 1. Project Overview\n",
    "This project aims to classify songs into genres using their lyrical content. By leveraging transformer-based models like BERT and RoBERTa, we intend to capture the contextual relationships within lyrics. The goal is to accurately predict genres such as Pop, Rock, Hip-Hop, Jazz, and others based on song lyrics. The results will enhance music recommendation systems, improve search algorithms, and provide insights into lyrical patterns across genres.\n",
    "\n",
    "# 2. Dataset\n",
    "The provided datasets include CSV files with labeled genres: Jazz, Electronic, Country, Hip-Hop, Rock, and Pop.\n",
    "Each dataset contains columns like Genre, Title, Artist, and Lyrics.\n",
    "Preprocessing steps will include:\n",
    "Tokenizing lyrics into words or tokens.\n",
    "Removing stop-words and non-contributive terms.\n",
    "Applying lemmatization or stemming.\n",
    "Cleaning text (e.g., removing special characters, punctuation, and converting text to lowercase).\n",
    "# 3. Methodology\n",
    "## a. Preprocessing\n",
    "Clean datasets to ensure consistent formatting.\n",
    "Merge all CSV files into a single dataset for unified processing.\n",
    "Handle missing lyrics by excluding those rows from training.\n",
    "Tokenize and create embeddings using pre-trained models like Word2Vec or GloVe.\n",
    "## b. Modeling\n",
    "Primary Models: BERT, RoBERTa for capturing deep contextual relationships.\n",
    "Baseline Models:\n",
    "TF-IDF combined with classifiers like SVM, Naive Bayes.\n",
    "CNN and LSTM for sequential data classification.\n",
    "Use transfer learning by fine-tuning BERT or RoBERTa on the dataset.\n",
    "## c. Evaluation\n",
    "Metrics: Accuracy, Precision, Recall, F1-Score, and ROC-AUC.\n",
    "Confusion matrices to analyze genre overlaps and misclassifications.\n",
    "Cross-validation (5-fold) to ensure generalization.\n",
    "## d. Ablation Study\n",
    "Analyze the impact of preprocessing techniques on model performance.\n",
    "Compare transformer-based models with traditional baselines to highlight their benefits.\n",
    "# 4. Tools and Libraries\n",
    "Python Libraries: TensorFlow, PyTorch, Hugging Face, nltk, scikit-learn, pandas, matplotlib.\n",
    "Data Processing: NLTK, SpaCy.\n",
    "Visualization: Matplotlib, Seaborn.\n",
    "# 5. Deliverables\n",
    "Code and Dataset: Well-structured code with clear comments and instructions.\n",
    "Final Report:\n",
    "Key observations on preprocessing, modeling, and evaluation.\n",
    "Detailed discussion on model performance and insights.\n",
    "Future improvements and research directions.\n",
    "Presentation: Recorded 10-minute video summarizing the project’s approach and results.\n",
    "# 6. Timeline\n",
    "Week 9: Preprocess datasets, clean text, and perform EDA (Exploratory Data Analysis).\n",
    "Week 10: Train baseline models (SVM, CNN, LSTM) and start implementing BERT/RoBERTa.\n",
    "Week 11: Fine-tune models, evaluate performance, and compare results.\n",
    "Week 12: Conduct ablation studies, finalize results, and generate visualizations.\n",
    "Week 13: Prepare the final report and presentation.\n",
    "# 7. Responsibilities\n",
    "As a solo project, all tasks, including data preprocessing, model implementation, evaluation, and report preparation, will be managed independently.\n",
    "\n",
    "If you'd like, I can also help generate code or reports for specific tasks, such as preprocessing, model training, or visualization. Let me know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6dc50-5d2f-48a9-bb58-82bca6b3b5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d7eb7e-721f-4e51-b9e7-94082272cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7505d869-1a0e-41b9-bdae-48b9a6c2bccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Genre                                        Title               Artist  \\\n",
      "0  Jazz  It's Beginning to Look a Lot like Christmas        Michael Bublé   \n",
      "1  Jazz                        Holly Jolly Christmas        Michael Bublé   \n",
      "2  Jazz               Christmas Time Is Here - Vocal  Vince Guaraldi Trio   \n",
      "3  Jazz                        Holly Jolly Christmas        Michael Bublé   \n",
      "4  Jazz                Santa Claus Is Coming to Town        Michael Bublé   \n",
      "\n",
      "                                              Lyrics  \n",
      "0  [Verse 1]\\nIt's beginning to look a lot like C...  \n",
      "1  Have a holly, jolly Christmas\\nIt's the best t...  \n",
      "2  \"Jingle Bells\" - Duke Ellington\\n\"When There's...  \n",
      "3  Have a holly, jolly Christmas\\nIt's the best t...  \n",
      "4  You better watch out\\nYou better not cry\\nYou ...  \n",
      "Dataset shape: (5470, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned lyrics dataset\n",
    "cleaned_lyrics_data = pd.read_csv(\"cleaned_lyrics_dataset.csv\")\n",
    "\n",
    "# Check the first few rows to ensure it loaded correctly\n",
    "print(cleaned_lyrics_data.head())\n",
    "\n",
    "# Print the shape of the dataset to verify\n",
    "print(f\"Dataset shape: {cleaned_lyrics_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210d753-324d-4c96-a810-7d384a6647ab",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9278f44b-a66b-498c-8cda-03caf52fb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (lyrics) and labels (genres)\n",
    "X = cleaned_lyrics_data['Lyrics']\n",
    "y = cleaned_lyrics_data['Genre']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55396533-9815-42af-86f9-471f48140f92",
   "metadata": {},
   "source": [
    "# Transform Lyrics Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd64f70-0cd4-475a-b7fd-1e8a9fc38465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Limit to top 5000 features for simplicity\n",
    "\n",
    "# Fit and transform the training data; transform the testing data\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d0d70-28bf-4a58-bc35-1d4fbf68c7e6",
   "metadata": {},
   "source": [
    "# Train and Evaluate Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79005d52-cec6-47c4-8e78-9426f927bb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Results for Logistic Regression:\n",
      "Accuracy: 0.5155\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.62      0.68      0.65       195\n",
      "  Electronic       0.44      0.57      0.50       218\n",
      "     Hip-Hop       0.64      0.56      0.59       162\n",
      "        Jazz       0.55      0.21      0.30       114\n",
      "         Pop       0.47      0.67      0.55       258\n",
      "        Rock       0.45      0.14      0.21       147\n",
      "\n",
      "    accuracy                           0.52      1094\n",
      "   macro avg       0.53      0.47      0.47      1094\n",
      "weighted avg       0.52      0.52      0.49      1094\n",
      "\n",
      "Confusion Matrix:\n",
      "[[132  30   4   3  18   8]\n",
      " [ 18 124  16   6  48   6]\n",
      " [ 14  16  90   2  40   0]\n",
      " [  8  47   8  24  25   2]\n",
      " [ 15  31  21   9 174   8]\n",
      " [ 25  32   2   0  68  20]]\n",
      "--------------------------------------------------\n",
      "Training SVM...\n",
      "Results for SVM:\n",
      "Accuracy: 0.5037\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.66      0.64      0.65       195\n",
      "  Electronic       0.47      0.63      0.54       218\n",
      "     Hip-Hop       0.61      0.54      0.57       162\n",
      "        Jazz       0.52      0.19      0.28       114\n",
      "         Pop       0.43      0.63      0.51       258\n",
      "        Rock       0.34      0.11      0.16       147\n",
      "\n",
      "    accuracy                           0.50      1094\n",
      "   macro avg       0.50      0.46      0.45      1094\n",
      "weighted avg       0.50      0.50      0.48      1094\n",
      "\n",
      "Confusion Matrix:\n",
      "[[125  29   5   3  22  11]\n",
      " [ 11 138  12   8  45   4]\n",
      " [ 10  14  88   2  47   1]\n",
      " [  9  48   8  22  23   4]\n",
      " [ 15  32  31   7 162  11]\n",
      " [ 20  35   1   0  75  16]]\n",
      "--------------------------------------------------\n",
      "Training Naive Bayes...\n",
      "Results for Naive Bayes:\n",
      "Accuracy: 0.4232\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.54      0.75      0.63       195\n",
      "  Electronic       0.49      0.26      0.34       218\n",
      "     Hip-Hop       0.56      0.33      0.41       162\n",
      "        Jazz       0.38      0.03      0.05       114\n",
      "         Pop       0.34      0.79      0.47       258\n",
      "        Rock       1.00      0.01      0.01       147\n",
      "\n",
      "    accuracy                           0.42      1094\n",
      "   macro avg       0.55      0.36      0.32      1094\n",
      "weighted avg       0.53      0.42      0.36      1094\n",
      "\n",
      "Confusion Matrix:\n",
      "[[147   6   3   1  38   0]\n",
      " [ 31  56  11   2 118   0]\n",
      " [ 10  10  53   1  88   0]\n",
      " [ 24  26   4   3  57   0]\n",
      " [ 27   4  23   1 203   0]\n",
      " [ 34  13   0   0  99   1]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Naive Bayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train_tfidf, y_train)  # Train the model\n",
    "    y_pred = model.predict(X_test_tfidf)  # Predict on test data\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e42653d-1095-49e2-9934-90b1e3d7f108",
   "metadata": {},
   "source": [
    "Analysis of Results\n",
    "1. Logistic Regression\n",
    "Accuracy: ~51.55%\n",
    "Best Classified Genres:\n",
    "Country: Precision 0.62, Recall 0.68\n",
    "Pop: Precision 0.47, Recall 0.67\n",
    "Issues:\n",
    "Jazz and Rock are misclassified often, with low Recall (Jazz: 0.21, Rock: 0.14).\n",
    "2. SVM\n",
    "Accuracy: ~50.37%\n",
    "Best Classified Genres:\n",
    "Country: Precision 0.66, Recall 0.64\n",
    "Electronic: Precision 0.47, Recall 0.63\n",
    "Issues:\n",
    "Similar to Logistic Regression, Jazz and Rock are challenging to classify.\n",
    "3. Naive Bayes\n",
    "Accuracy: ~42.32%\n",
    "Best Classified Genres:\n",
    "Country: Precision 0.54, Recall 0.75\n",
    "Pop: Precision 0.34, Recall 0.79\n",
    "Issues:\n",
    "Extremely poor performance for Jazz and Rock (F1-scores ~0.05 and ~0.01).\n",
    "\n",
    "Insights\n",
    "Class Imbalance: Genres like Jazz and Rock have fewer samples compared to Pop or Country. This imbalance likely impacts their classification.\n",
    "Naive Bayes: Performs poorly, possibly due to its assumption of feature independence, which doesn't hold well for text data like lyrics.\n",
    "TF-IDF Limitations: While TF-IDF captures word importance, it doesn't account for word order or context, which are crucial for understanding lyrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90495b86-a0e1-4d7a-bdda-edcb0cd5eacd",
   "metadata": {},
   "source": [
    "# Step 3: Addressing Class Imbalance\n",
    "Objective\n",
    "To improve model performance, especially for underrepresented genres like Jazz and Rock, by balancing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc8fd2d-138a-47e2-a950-5f784e24f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "Approach\n",
    "1. Analyze Class Distribution: Confirm the extent of imbalance.\n",
    "2. Apply Resampling Techniques:\n",
    "Oversampling minority classes (e.g., using SMOTE).\n",
    "Undersampling majority classes.\n",
    "Class Weights in model training.\n",
    "3. Evaluate Impact: Retrain baseline models to observe improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1ef0e0-d555-419f-a9cf-f670a82fc187",
   "metadata": {},
   "source": [
    "## 1. Analyze Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4452c75d-5ece-418c-a6e5-e49d2662121c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre Distribution Before Resampling:\n",
      "Genre\n",
      "Pop           1290\n",
      "Electronic    1088\n",
      "Country        978\n",
      "Hip-Hop        808\n",
      "Rock           734\n",
      "Jazz           572\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting genre distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "genre_counts = cleaned_lyrics_data['Genre'].value_counts()\n",
    "print(\"Genre Distribution Before Resampling:\")\n",
    "print(genre_counts)\n",
    "\n",
    "# Plot\n",
    "genre_counts.plot(kind='bar')\n",
    "plt.title('Number of Songs per Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84fce14-14fd-484b-83e0-432769c5b0a9",
   "metadata": {},
   "source": [
    "# 2. Apply Resampling Techniques\n",
    "We'll use Synthetic Minority Over-sampling Technique (SMOTE) to oversample minority classes.\n",
    "\n",
    "Install imbalanced-learn Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "937a9bc2-9526-4433-bab6-58f7f231d493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/lib/python3.12/site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bb84e22-b5ba-4a77-bac6-40d2b0f24369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre Distribution After SMOTE:\n",
      "Counter({3: 1290, 1: 1290, 0: 1290, 2: 1290, 5: 1290, 4: 1290})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode genres as numerical labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Apply TF-IDF vectorization again\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_tfidf, y_encoded)\n",
    "\n",
    "# Verify new class distribution\n",
    "from collections import Counter\n",
    "print(\"Genre Distribution After SMOTE:\")\n",
    "print(Counter(y_resampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182772dd-e75f-4d9e-a68d-89f403b25586",
   "metadata": {},
   "source": [
    "Label Encoding: Convert genre labels to integers for SMOTE.\n",
    "Resampling: SMOTE synthesizes new examples for minority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b3056-b4c0-433d-af46-939a4d38ec4e",
   "metadata": {},
   "source": [
    "# 3. Retrain Baseline Models on Resampled Data\n",
    "Split Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6f8619e-7743-4e8c-8ded-5adec01a7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the resampled data\n",
    "X_train_res, X_test_res, y_train_res, y_test_res = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2cfa08-096e-4104-aa83-2bd07dd35349",
   "metadata": {},
   "source": [
    "Train and Evaluate Models\n",
    "Repeat the training and evaluation code from earlier, but use the resampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3579d11e-9ce2-4e20-8ec7-8d3c5dd3fca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression on Resampled Data...\n",
      "Results for Logistic Regression:\n",
      "Accuracy: 0.6344\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.69      0.77      0.73       258\n",
      "  Electronic       0.59      0.51      0.55       258\n",
      "     Hip-Hop       0.67      0.78      0.72       258\n",
      "        Jazz       0.67      0.73      0.70       258\n",
      "         Pop       0.52      0.44      0.48       258\n",
      "        Rock       0.62      0.58      0.60       258\n",
      "\n",
      "    accuracy                           0.63      1548\n",
      "   macro avg       0.63      0.63      0.63      1548\n",
      "weighted avg       0.63      0.63      0.63      1548\n",
      "\n",
      "Confusion Matrix:\n",
      "[[198  13   7  17   9  14]\n",
      " [  8 132  20  43  33  22]\n",
      " [  7  14 201   8  25   3]\n",
      " [ 10  21  13 189  12  13]\n",
      " [ 25  22  48  11 113  39]\n",
      " [ 40  20  10  14  25 149]]\n",
      "--------------------------------------------------\n",
      "Training SVM on Resampled Data...\n",
      "Results for SVM:\n",
      "Accuracy: 0.6899\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.75      0.81      0.77       258\n",
      "  Electronic       0.59      0.67      0.63       258\n",
      "     Hip-Hop       0.74      0.77      0.75       258\n",
      "        Jazz       0.82      0.74      0.78       258\n",
      "         Pop       0.52      0.56      0.54       258\n",
      "        Rock       0.77      0.60      0.67       258\n",
      "\n",
      "    accuracy                           0.69      1548\n",
      "   macro avg       0.70      0.69      0.69      1548\n",
      "weighted avg       0.70      0.69      0.69      1548\n",
      "\n",
      "Confusion Matrix:\n",
      "[[208  20   6   4  10  10]\n",
      " [  4 174  10  24  38   8]\n",
      " [  7  13 198   2  35   3]\n",
      " [  8  36   7 190  11   6]\n",
      " [ 17  29  40   9 144  19]\n",
      " [ 35  22   6   3  38 154]]\n",
      "--------------------------------------------------\n",
      "Training Naive Bayes on Resampled Data...\n",
      "Results for Naive Bayes:\n",
      "Accuracy: 0.5168\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.50      0.86      0.63       258\n",
      "  Electronic       0.62      0.11      0.18       258\n",
      "     Hip-Hop       0.61      0.71      0.65       258\n",
      "        Jazz       0.61      0.54      0.57       258\n",
      "         Pop       0.54      0.29      0.38       258\n",
      "        Rock       0.40      0.59      0.47       258\n",
      "\n",
      "    accuracy                           0.52      1548\n",
      "   macro avg       0.54      0.52      0.48      1548\n",
      "weighted avg       0.54      0.52      0.48      1548\n",
      "\n",
      "Confusion Matrix:\n",
      "[[222   0   7  12   1  16]\n",
      " [ 48  28  31  51  20  80]\n",
      " [ 21   1 183   4  30  19]\n",
      " [ 31  11  22 139   5  50]\n",
      " [ 56   3  45  11  76  67]\n",
      " [ 69   2  13  12  10 152]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models_resampled = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Naive Bayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models_resampled.items():\n",
    "    print(f\"Training {model_name} on Resampled Data...\")\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_pred_res = model.predict(X_test_res)\n",
    "    \n",
    "    # Convert numerical labels back to genres\n",
    "    y_test_labels = le.inverse_transform(y_test_res)\n",
    "    y_pred_labels = le.inverse_transform(y_pred_res)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test_labels, y_pred_labels):.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test_labels, y_pred_labels))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test_labels, y_pred_labels))\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6cb8cb-22df-40b5-aedd-4ee5dd3c84ec",
   "metadata": {},
   "source": [
    "Analysis\n",
    "Compare Metrics: See if recall and precision for minority classes improved.\n",
    "Document Findings: Note any significant changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def0127-8587-406c-adce-de608a909c71",
   "metadata": {},
   "source": [
    "# Step 4: Implementing Advanced Models\n",
    "Objective\n",
    "To build more sophisticated models that can capture the contextual and sequential nature of song lyrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37ac7ec-d575-45f4-a0fc-41f60bb66e8f",
   "metadata": {},
   "source": [
    "Options\n",
    "1. Recurrent Neural Networks (RNNs): Use LSTM models.\n",
    "2. Convolutional Neural Networks (CNNs): Apply 1D CNNs for text classification.\n",
    "3. Transformer-Based Models: Fine-tune pre-trained models like BERT.\n",
    "Given your project proposal focuses on transformer-based models, we'll prioritize that.\n",
    "\n",
    "Implementing BERT for Genre Classification\n",
    "1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e7a3ed7-2941-4e16-8ca7-64dc07a0e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl (381 kB)\n",
      "Downloading tokenizers-0.20.3-cp312-cp312-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.3 safetensors-0.4.5 tokenizers-0.20.3 transformers-4.46.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b77c35e-76bc-4ac6-9f46-c9055a974074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Using cached torch-2.5.1-cp312-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Installing collected packages: sympy, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed sympy-1.13.1 torch-2.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75d46076-15c7-4583-a7f1-20dedee218ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e105621a-f0d0-47b2-af50-9235826e82a9",
   "metadata": {},
   "source": [
    "## 3. Prepare Data\n",
    "Tokenization and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ff90650-bc49-42a7-8ce7-b6ba091474ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bafc682f438a4d6193dcbc5723bc92c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b4482834314364b8f2cc7cab0adcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ab34c748bc4d5a81b3ddb35a9d5e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22f1dae304f460d8d7036b3869f6b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Maximum length for padding/truncating\n",
    "MAX_LEN = 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6714273-2c63-4e6d-bb92-7ccf7df1b8c0",
   "metadata": {},
   "source": [
    "Create Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e48a3db-8a45-4b1e-94bd-3a1e4f054129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f348723d-43c0-4a2f-b0ee-7eb68a73d99b",
   "metadata": {},
   "source": [
    "Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f32760f1-251b-4690-852f-c9106ba13f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    cleaned_lyrics_data['Lyrics'], y_encoded, test_size=0.1, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = LyricsDataset(X_train, y_train, tokenizer, MAX_LEN)\n",
    "val_dataset = LyricsDataset(X_val, y_val, tokenizer, MAX_LEN)\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866b6146-473a-430c-a3ae-d6b3d8ed4de5",
   "metadata": {},
   "source": [
    "## 4. Initialize BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85b980db-1105-4fd5-a972-c06c0dca697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa09fe6e61a47b2a421f808198361ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=len(le.classes_),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35389128-ca2e-45a0-8dce-e71833b19037",
   "metadata": {},
   "source": [
    "## 5. Set Up Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f011b407-f6c5-4111-acef-00ee83e9bd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2046cf6a-97c2-4fd7-9169-4ee784dcc4bb",
   "metadata": {},
   "source": [
    "## 6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a63bd41c-7672-4492-8ceb-82e60f12aa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 616/616 [53:02<00:00,  5.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.7752039687974113\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 616/616 [52:33<00:00,  5.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.774516771753113\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 616/616 [52:15<00:00,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.7728955348977795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Training loss: {avg_train_loss}')\n",
    "    \n",
    "    # Validation loop can be added here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d8f18-4997-407d-9f53-018e9a427663",
   "metadata": {},
   "source": [
    "# 7. Evaluation\n",
    "Implement a validation loop to evaluate the model after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e604492-4e7b-4657-ba53-e43eb005b97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Model Evaluation:\n",
      "Accuracy: 0.2377\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.00      0.00      0.00        98\n",
      "  Electronic       1.00      0.01      0.02       109\n",
      "     Hip-Hop       0.00      0.00      0.00        81\n",
      "        Jazz       0.00      0.00      0.00        57\n",
      "         Pop       0.24      1.00      0.38       129\n",
      "        Rock       0.00      0.00      0.00        73\n",
      "\n",
      "    accuracy                           0.24       547\n",
      "   macro avg       0.21      0.17      0.07       547\n",
      "weighted avg       0.25      0.24      0.09       547\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "        \n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert labels back to genres\n",
    "pred_genres = le.inverse_transform(predictions)\n",
    "true_genres = le.inverse_transform(true_labels)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"BERT Model Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(true_genres, pred_genres):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_genres, pred_genres))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13364fe-1b3f-4e81-8ead-590394fa91e5",
   "metadata": {},
   "source": [
    "Notes\n",
    "GPU Usage: Training BERT can be resource-intensive. If you don't have a GPU, consider using Google Colab.\n",
    "Hyperparameters: Adjust EPOCHS, BATCH_SIZE, and MAX_LEN based on your dataset and computational resources.\n",
    "Validation: Implement early stopping or learning rate schedulers for better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4bae18-9512-4a85-a170-4a61f16d732b",
   "metadata": {},
   "source": [
    "Alternative Models\n",
    "If time permits, you can implement LSTM or CNN models for comparison.\n",
    "\n",
    "Step 5: Evaluate and Compare Models\n",
    "Objective\n",
    "To compare the performance of baseline models and advanced models, analyzing strengths and weaknesses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071c5b79-26ff-4036-8a10-bbdcfc5e9f16",
   "metadata": {},
   "source": [
    "Approach\n",
    "1. Collect Metrics: Accuracy, precision, recall, F1-score for all models.\n",
    "2. Visualization: Plot metrics for comparison.\n",
    "3. Confusion Matrices: Analyze misclassifications.\n",
    "4. Document Findings: Prepare detailed analysis for your report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017373a-ec9d-44b0-9718-d2297fd30ded",
   "metadata": {},
   "source": [
    "# Code for Comparing Models\n",
    "Collect Metrics in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1aeff-0a66-497e-a464-715f6b0c187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example structure\n",
    "results = {\n",
    "    'Model': ['Logistic Regression', 'SVM', 'Naive Bayes', 'BERT'],\n",
    "    'Accuracy': [0.5155, 0.5037, 0.4232, bert_accuracy],\n",
    "    'Precision': [log_reg_precision, svm_precision, nb_precision, bert_precision],\n",
    "    'Recall': [log_reg_recall, svm_recall, nb_recall, bert_recall],\n",
    "    'F1-Score': [log_reg_f1, svm_f1, nb_f1, bert_f1]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e1be1-28cd-4a66-8e69-7c0782afc482",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a684ec88-9b48-48b0-9008-a1c7f0b83ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot accuracy comparison\n",
    "sns.barplot(x='Model', y='Accuracy', data=results_df)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c43992e-b552-4fad-b6f2-bcc7d6a04d36",
   "metadata": {},
   "source": [
    "Step 6: Documenting and Preparing the Report\n",
    "Structure of the Report\n",
    "Introduction\n",
    "Overview of the project.\n",
    "Importance of genre classification using lyrics.\n",
    "Dataset and Preprocessing\n",
    "Describe the dataset.\n",
    "Explain preprocessing steps and challenges.\n",
    "Baseline Models\n",
    "Methodology.\n",
    "Results and analysis.\n",
    "Advanced Models\n",
    "Implementation details.\n",
    "Hyperparameter settings.\n",
    "Results and analysis.\n",
    "Comparison and Discussion\n",
    "Compare all models.\n",
    "Discuss strengths and weaknesses.\n",
    "Conclusion\n",
    "Summarize findings.\n",
    "Potential future work.\n",
    "References\n",
    "Cite all sources and libraries used.\n",
    "Preparation for Presentation\n",
    "Slides Outline:\n",
    "Introduction and objectives.\n",
    "Methodology (brief).\n",
    "Key results and visualizations.\n",
    "Conclusion and future work.\n",
    "Tips:\n",
    "Keep slides concise.\n",
    "Use visuals to enhance understanding.\n",
    "Practice timing to fit within 10 minutes.\n",
    "Final Notes\n",
    "Code Quality: Ensure your code is well-commented and organized.\n",
    "Instructions: Provide clear instructions on how to run your code.\n",
    "Dataset Sharing: Since datasets can be large, provide a link if necessary.\n",
    "Project Alignment: Your project aligns well with the requirements, focusing on implementing an NLP task using public datasets and incorporating multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078e2c0-0f41-4ab2-af1f-c12af4b9bc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3746d8-b1b1-46a5-b2ac-47230d71f95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c98cf-602f-4553-9e5f-be7375a50d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf144bff-03e8-4c1d-8de7-bc0879a13c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a472d4-4149-432a-b234-76402847590c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44fd5d8-0a41-4654-bb95-3a9c551ab74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa76f9-2533-4dcf-a16b-778e3910c5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a392a63b-d581-405a-998a-52667c2d03f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52263a13-6bcb-4471-a892-6b2298ba216b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
